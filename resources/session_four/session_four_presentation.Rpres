An Introduction to the Tidyverse | Session Four
====================================
author: Tim Hargreaves
date: 2019-10-24
width: 1440
height: 900
css: presentation.css

Recap
====================================
type: section

```{r echo=FALSE}
knitr::opts_chunk$set(dpi = 70, dev.args = list(type = "cairo"))
```

Statistics in R
====================================

* R has many useful statistical functions:
  * `mean()`, `median()`, `min()`, `max()`, `quantile()[i]`
  * `range()`, `diff()`, `IQR()`
  * `var()`, `sd()`
* Remember to use `na.rm = TRUE` if you have missing values

Comparisons and Boolean operators
====================================

* Comparisons in R can be done with `<`, `<=`, `>`, and `>=`
* Equality can be checked with `==`, `!=`, and `near()`
* R has three main Boolean operators `&` (and), `|` (or), and `!` (not)
* All of these comparisons and Boolean operators are vectorised

The dplyr Verbs
====================================

* There are five key `dplyr` functions referred to as verbs:
  * `filter()` - pick observations by their values
  * `arrange()` - reorder observations based on their values
  * `select()` - pick variables by their names
  * `mutate()` - create new variables as functions of existing variables
  * `summarise()`/`summarize()` - collapse many values down to a single summary
* These can be combined with `group_by()` to change the scope of aggregate functions
* When using multiple verbs, combine them with the pipe (`%>%`) operator

Tidy Data
====================================
type: section

Introduction
====================================
type: sub-section

Where Are We?
====================================

* _"Tidy datasets are all alike; but every messy dataset is messy in its own way"_ - Hadley Wickham
* This session is all about organising your data in a consistent way called _tidy data_
* This organisation scheme requires some work upfront but pays off in the long-run by making it much simpler to use the tools in the tidyverse

![Data Analysis Map - Tidy](images/data_analysis_map_tidy.png)

What is tidyr?
====================================
left: 70%

* `tidyr` is the foundational package in the tidyverse
*  It allows you to take a dataset in a non-tidy form and transform it into tidy data
*  Once data is in a tidy form, you can spend much less time munging data from one representation to another, allowing more time to answer difficult analytical questions

***

![tidyr Hex](images/tidyr_hex.png)

Data Representations
====================================

* You can represent the same underlying data in multiple ways
* The following example shows four different ways to organise the same data
* Each dataset shows the same values of four variables, `country`, `year`, `population`, and `cases`
* Only one of these is tidy data. Which will discuss which one this is at a later point

```{r echo=FALSE}
library(tidyverse)
```


Data Representations (cont.)
====================================

```{r}
table1
```

Data Representations (cont.)
====================================

```{r}
table2
```

Data Representations (cont.)
====================================

```{r}
table3
```

Data Representations (cont.)
====================================

```{r}
table4a
```

```{r}
table4b
```

Tidy Data
====================================

* These are all representations of the same underlying data
* Despite this, they are not all equally easy to use
* Only one of these datasets is in a tidy format
* The tidy dataset will be much easier to work with inside of the tidyverse

Tidy Data (cont.)
====================================

* There a three interrelated rules which make a dataset tidy:

  1. Each variable (a value you can measure) must have its own column
  2. Each observation (a thing which has measurable properties) must have its own row
  3. Each value must have its own cell

* We can using the following graphic to represent this visually

![Tidy Data Rules](images/tidy_data_rules.png)

Tidy Data (cont.)
====================================

* These rules are interrelated since it's impossible to only satisfy two of the three
* This interrelationship leads to an even simpler set of practical instructions:

  1. Put each dataset in tibble
  2. Put each variable in it's own column


* According to these rules, only the first representation is tidy

```{r echo=FALSE}
table1
```

* We can now look at why the other representations are not tidy and how we can fix this

Gathering
====================================
type: sub-section

An Untidy Example
====================================

* Let's start by having a look at the first tibble in the fourth representation

```{r}
table4a
```

* This representation violates the first rule of tidy data - each variable must have its own column
* Here we have two columns, `1999` and `2000`, which do not represent variables
* Instead they represent specific values of the `year` variable
* As a consequence, it also violates the second rule - each observation must have its own row
* This is because each row two observations, one from each year

Tidying the Dataset
====================================

* To tidy a dataset like this we need to _gather_ those two non-variable columns into a new pair of variables
* To describe this operation we need three parameters:
  * The set of columns that are not variables (`1999` and `2000` in this case)
  * The name of the variable whose values form the column names (we said before that this is `year`). We refer to this as the `key`
  * The name of the variable whose values are spread over the cells (here it is `cases`). We refer to this as the `value`
  
Tidying the Dataset (cont.)
====================================

* We can use these parameters in a call to `gather()`

```{r}
table4a %>%
  # use backticks so R doesn't confuse the column names for numbers
  gather(`1999`, `2000`, key = "year", value = "cases")
```

* We could perform a similar process to tidy `table4b` though this time our `value` would be `"population"`
* To combine these two tables we would then have to use techniques covered later in this session

Diagramming the Transformation
====================================

* We can use the following diagram to show the gathering process we just performed:

![Gathering](images/gathering.png)

Spreading
====================================
type: sub-section

An Untidy Example
====================================

* Now let's take a look at the second representation

```{r}
table2
```

* This suffers from the opposite problem of the last representation
* Each observation is scattered across two rows and the variables `cases` and `population` are contained in the `type` column

Tidying the Dataset
====================================

* We can use the `spread()` function to fix this issue
* This time we only need two parameters:
  * The column which contains the variable names (here, it's `type`) which we referred to as the `key`
  * The column that contains values from multiple variables (here it's `count`) which we referred to as the `value`
  
Tidying the Dataset (cont.)
====================================

* We can use these parameters in a call to `spread()`

```{r}
table2 %>%
  spread(key = type, value = count)
```

* We don't have to use quotes for `type` and `count` since they already exist in the dataset whereas with `gather()` we were adding them

Diagramming the Transformation
====================================

* We can use the following diagram to show the spreading process we just performed:

![Gathering](images/spreading.png)

Spreading and Gathering
====================================

* As you might be able to guess from the common `key` and `value` arguments, `spread()` and `gather()` are opposites of each other and can be used to reverse each other's effects
* `gather()` makes wide tables narrower and longer, whereas `spread()` makes long tables shorter and wider

Separating
====================================
type: sub-section

An Untidy Example
====================================

* The last representation to look at is number three

```{r}
table3
```

* This violates the last rule of tidy data - each value must have its own cell
* As a consequence we also end up with a non-variable column `rate`

Tidying the Dataset
====================================

* We can use the `separate()` function to fix this issue
* We will need to specify two parameters:
  * The column that we want to split into multiple columns wherever a separator character appears
  * The names of the new columns to create as a character vector
* By default `separate()` will split values whenever it sees a non-alphanumeric character though this can be specified manually using the `sep` argument
* We also need to specify `convert = TRUE` if we want `tidyr` to automatically convert the new columns to the correct data types (by default they would still be characters)
  
Tidying the Dataset (cont.)
====================================

* We then use these parameters in a call to `separate()`

```{r}
table3 %>%
  separate(rate, into = c('cases', 'population'), sep = '/', convert = TRUE)
```

* **Bonus Note:** You can pass `separate()` a vector of integers as the `sep` argument to be used as the positions to split at

Diagramming the Transformation
====================================

* We can use the following diagram to show the spreading process we just performed:

![Separating](images/separating.png)

Uniting
====================================
type: sub-section

An Untidy Example
====================================

* Here is another representation of the dataset we've been looking that we did not include earlier

```{r}
table5
```

* This violates the last rule of tidy data too but in an opposite way
* Here, the value of year has been split up into two cells, one containing the century and one containing the rest

Tidying the Dataset
====================================

* We can use the `unite()` function to fix this issue
* We will need to specify the following parameters:
  * The name of the new column to create
  * The set of columns to combine
* Optionally, we can also include a `sep` argument to specify the separator or use the default `_`
  
Tidying the Dataset (cont.)
====================================

* We then use these parameters in a call to `unite()`

```{r}
table5 %>%
  unite(new, century, year, sep = '')
```

Diagramming the Transformation
====================================

* We can use the following diagram to show the spreading process we just performed:

![Separating](images/uniting.png)

Relational Data
====================================
type: section

Introduction
====================================
type: sub-section

Where Are We?
====================================

* We now make a return to the transformation part of the data analysis pipeline
* It's rare that a data analysis only contains a single table of data so in this section we learn how to combine tables to answer questions we are interested in
* We will be using `dpylr` to help us do this using a new set of functions from the package

![Data Analysis Map - Transform](images/data_analysis_map_transform.png)

Relationships
====================================

* Relations are always defined between pairs of tables. All other relations are built up from this simple idea: the relations of three or more tables are always a property of the relations between the pairs
* There are many ways to deal with relational data but due to time constraints, we will only be looking at the most critical types - _mutating joins_
* The other two main types are _filtering joins_ and _set operations_. These can be read about in R4DS chapter 10 if you need these for your work in the DataViz battle

Mutating Joins
====================================
type: sub-section

Introduction
====================================

* A mutating join allows you to combine variables from two tables
* This is performed by matching observations on a collection of columns (or single column) known as the key
* There are different types of joins which handle missing values in different ways
* Any join takes two main arguments
  * A table to be joined with
  * A single column name or vector of column names to be used as the key
* The output of a join contains the shared keys as well as the other columns from both tables
  
Band Membership
====================================

* To illustrate the various join types, we use the following toy dataset made of two tables

```{r}
band_members
```

```{r}
band_instruments
```

Inner Join
====================================

* The inner join is the simplest join
* It matches pairs of observations whenever their keys are equal
* The output of an inner join only contains rows which contained the key in both tables

```{r}
band_members %>%
  inner_join(band_instruments, by = 'name')
```

* Here, neither Mick nor Keith are included in the result as they don't appear in both tables

Left Join
====================================

* A left join will result in a table containing every value of the key appearing in the piped-in table
* Any missing values will be filled in with `na`
* It is called a left join since the keys that are preserved come from the table used as the left argument

```{r}
band_members %>%
  left_join(band_instruments, by = 'name')
```

* Here the result contains all 3 musicians featured in the `band_members` table

Right Join
====================================

* A right join is the opposite of a left join
* It preserves all keys that come from the table used as the right argument

```{r}
band_members %>%
  left_join(band_instruments, by = 'name')
```

* Here the result contains all 3 musicians featured in the `band_instruments` table

Full Join
====================================

* A full join combines the behaviour of a left and right join
* It creates a row in the result for every key that appears in either table

```{r}
band_members %>%
  full_join(band_instruments, by = 'name')
```

Differing Key Column Names
====================================

* It is not always the case that your key columns will have the same names
* Here is an altered version of the previous problem demonstrating this:

```{r}
names(band_members)
```

```{r}
names(band_instruments2)
```

* We can still perform joins but we have to slightly modify our syntax to the following

```{r}
band_members %>% inner_join(band_instruments2, by = c("name" = "artist"))
```

Duplicate Keys
====================================

* Mutating joins also work when one table has duplicate keys
* Detailed discussion of this is beyond the scope of this course but here is a brief example

```{r}
employees <- tibble(name = c('John', 'Anne'), experience = c(4, 7))
sales <- tibble(item_code = c('21', '52', '35'), sold_by = c('John', 'Anne', 'Anne'))
sales %>%
  inner_join(employees, by = c('sold_by' = 'name'))
```

Application to the Weather Dataset
====================================

Question: How did daily total rainfall differ between 1987 and 2015 in Camborne?

```{r}
# import tables using readr exported from Excel as CSV
# keep only relevant columns
# note: I had to manually go in and remove the last few lines of the CSV
rainfall_1987 <- read_csv('data/camborne_may_oct_1987.csv',
                          skip = 5,
                          col_types = cols(.default = col_skip(),
                                           Date = col_date('%d/%m/%Y'),
                                           `Daily Total Rainfall (0900-0900) (mm)` = col_character())) %>%
  rename(date = Date,
         rainfall = `Daily Total Rainfall (0900-0900) (mm)`) %>%
  mutate(rainfall = ifelse(rainfall == 'tr', '0', rainfall),
         rainfall = as.numeric(rainfall))
```

We do the same for 2015 too creating `rainfall_2015`

```{r echo = FALSE}
rainfall_2015 <- read_csv('data/camborne_may_oct_2015.csv',
                          skip = 5,
                          col_types = cols(.default = col_skip(),
                                        Date = col_date('%d/%m/%Y'),
                                        `Daily Total Rainfall (0900-0900) (mm)` = col_character())) %>%
  rename(date = Date,
         rainfall = `Daily Total Rainfall (0900-0900) (mm)`) %>%
  mutate(rainfall = ifelse(rainfall == 'tr', '0', rainfall),
         rainfall = as.numeric(rainfall))
```

Application to the Weather Dataset (cont.)
====================================

```{r}
rainfall_1987
```

***

```{r}
rainfall_2015
```

Application to the Weather Dataset (cont.)
====================================

* Extract day of year and drop old date column

```{r}
rainfall_1987 <- rainfall_1987 %>%
  mutate(day_of_year = as.integer(format(date, '%j'))) %>%
  select(-date)
head(rainfall_1987)
```

* Again, we do the same for `rainfall_2015`

```{r echo=FALSE}
rainfall_2015 <- rainfall_2015 %>%
  mutate(day_of_year = as.integer(format(date, '%j'))) %>%
  select(-date)
```

Application to the Weather Dataset (cont.)
====================================

* We join the datasets
* We can use any join type since all keys are shared

```{r}
rainfall_combi <- rainfall_1987 %>%
  inner_join(rainfall_2015, by = 'day_of_year', 
             suffix = c('.1987', '.2015'))
head(rainfall_combi)
```

* We add suffixes to the column names using the `suffix` parameter

Application to the Weather Dataset (cont.)
====================================

* This representation is not tidy so will be difficult to plot
* Hence we use `gather()` to fix this

```{r}
rainfall_tidy <- rainfall_combi %>%
  gather(rainfall.1987, rainfall.2015, key='year', value='rainfall') %>%
  # change rainfall.1987 to just 1987
  mutate(year = str_replace(year, 'rainfall\\.', ''))
head(rainfall_tidy %>% arrange(day_of_year))
```

Application to the Weather Dataset (cont.)
====================================

* We are now ready to plot

```{r fig.width = 16, fig.align = 'center'}
ggplot(rainfall_tidy, aes(x = day_of_year, y = rainfall, col = year)) +
  geom_point(size = 2) +
  geom_line() +
  labs(x = 'Day of Year', y = 'Total Rainfall (mm)', col = 'Year') +
  theme_minimal()
```

